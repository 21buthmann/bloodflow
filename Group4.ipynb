{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3092,"status":"ok","timestamp":1737710148386,"user":{"displayName":"TR Fluide","userId":"15818092041118769586"},"user_tz":-60},"id":"uA0Fr5prJOP_","outputId":"c9ecbb10-7776-44c1-db3a-65559d86b54c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting meshio\n","  Downloading meshio-5.3.5-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from meshio) (1.26.4)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from meshio) (13.9.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->meshio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->meshio) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->meshio) (0.1.2)\n","Downloading meshio-5.3.5-py3-none-any.whl (166 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/166.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m163.8/166.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.2/166.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: meshio\n","Successfully installed meshio-5.3.5\n"]}],"source":["!pip install meshio\n","#!pip install torch-geometric torch-scatter"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14835,"status":"ok","timestamp":1737710163216,"user":{"displayName":"TR Fluide","userId":"15818092041118769586"},"user_tz":-60},"id":"dH53mKJcVKF9","outputId":"ad52bbe9-f875-4bee-a61e-72c18983330d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in links: https://data.pyg.org/whl/torch-2.5.1+cu121.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_scatter-2.1.2%2Bpt25cu121-cp311-cp311-linux_x86_64.whl (10.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.1.2+pt25cu121\n","Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n","  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-gknzl2c5\n","  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-gknzl2c5\n","  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 9b794b600d41802edaad26aac18bff958fc8f642\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.11.11)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (2024.10.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.1.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (1.26.4)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.2.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (4.67.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.18.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric==2.7.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (2024.12.14)\n","Building wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-2.7.0-py3-none-any.whl size=1170967 sha256=b21652b9bc692ab7286702097c0a61fd896354b862e13e2886146d57897f479c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ha3gctja/wheels/93/bb/85/bfec4ee59b2563f74ec87cc2c91c6a4d3e40d3dcdec8ee5afe\n","Successfully built torch-geometric\n","Installing collected packages: torch-geometric\n","Successfully installed torch-geometric-2.7.0\n"]}],"source":["import torch\n","!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n","\n","!pip install git+https://github.com/pyg-team/pytorch_geometric.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20103,"status":"ok","timestamp":1737710183304,"user":{"displayName":"TR Fluide","userId":"15818092041118769586"},"user_tz":-60},"id":"S2k41XJvUVRn","outputId":"a96a8494-ff1e-48f6-c289-35b3de23980c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k6yi5DK2Io9F"},"outputs":[],"source":["import numpy as np\n","import os\n","import tensorflow as tf\n","import torch\n","import meshio\n","from torch_geometric.data import Data\n","import zipfile\n","\n","import random\n","import pandas as pd\n","import torch_scatter\n","import torch.nn as nn\n","from torch.nn import Linear, Sequential, LayerNorm, ReLU\n","from torch_geometric.nn.conv import MessagePassing\n","from torch_geometric.data import DataLoader\n","\n","import time\n","import torch.optim as optim\n","from tqdm import trange\n","import copy\n","import matplotlib.pyplot as plt\n","from typing import List"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wV7YsJdsJIDo"},"outputs":[],"source":["def xdmf_to_meshes(xdmf_file_path: str) -> List[meshio.Mesh]:\n","    \"\"\"\n","    Opens an XDMF archive file, and extract a data mesh object for every timestep.\n","\n","    xdmf_file_path: path to the .xdmf file.\n","    Returns: list of data mesh objects.\n","    \"\"\"\n","\n","    reader = meshio.xdmf.TimeSeriesReader(xdmf_file_path)\n","    points, cells = reader.read_points_cells()\n","    meshes = []\n","\n","    # Extracting the meshes from the archive\n","    for i in range(reader.num_steps):\n","        # Depending on meshio version, the function read_data may return 3 or 4 values.\n","        try:\n","            time, point_data, cell_data, _ = reader.read_data(i)\n","        except ValueError:\n","            time, point_data, cell_data = reader.read_data(i)\n","        mesh = meshio.Mesh(points, cells, point_data=point_data, cell_data=cell_data)\n","        meshes.append(mesh)\n","    print(f\"Loaded {len(meshes)} timesteps from {xdmf_file_path.split('/')[-1]}\\n\")\n","    return meshes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"feHC2HfOIzq4"},"outputs":[],"source":["def tetra_to_edges(tetra):\n","  \"\"\"Computes mesh edges from tetrahedrons.\n","\n","  \"\"\"\n","  # collect edges from tetra\n","  edges = tf.concat([tetra[:, 0:2], # 1-2\n","                     tetra[:, 1:3], # 2-3\n","                     tetra[:, 2:4], # 3-4\n","                     tf.stack([tetra[:, 2], tetra[:, 0]], axis=1), # 3-1\n","                     tf.stack([tetra[:, 3], tetra[:, 0]], axis=1), # 4-1\n","                     tf.stack([tetra[:, 3], tetra[:, 1]], axis=1)], axis=0) # 4-2\n","  # those edges are sometimes duplicated (within the mesh) and sometimes\n","  # single (at the mesh boundary).\n","  # sort & pack edges as single tf.int64\n","  receivers = tf.reduce_min(edges, axis=1)\n","  senders = tf.reduce_max(edges, axis=1)\n","  packed_edges = tf.bitcast(tf.stack([senders, receivers], axis=1), tf.int64)\n","  # remove duplicates and unpack\n","  unique_edges = tf.bitcast(tf.unique(packed_edges)[0], tf.int32)\n","  senders, receivers = tf.unstack(unique_edges, axis=1)\n","  # create two-way connectivity\n","  return (tf.concat([senders, receivers], axis=0),\n","          tf.concat([receivers, senders], axis=0))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17462,"status":"ok","timestamp":1737710211298,"user":{"displayName":"TR Fluide","userId":"15818092041118769586"},"user_tz":-60},"id":"NzOxFtCiNDr5","outputId":"a41a860b-e6ce-4e4a-e32f-811eaf0d4363"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1W90lq3I_5RY-Ff48hjR3QoqBzHFAxOiR\n","From (redirected): https://drive.google.com/uc?id=1W90lq3I_5RY-Ff48hjR3QoqBzHFAxOiR&confirm=t&uuid=983d291c-15be-407a-bd3e-2eaaf9a24313\n","To: /content/IDSC2025_AnXplore03.zip\n","100% 1.45G/1.45G [00:12<00:00, 113MB/s]\n"]}],"source":["!gdown 1W90lq3I_5RY-Ff48hjR3QoqBzHFAxOiR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mxf3-I7uI2bX"},"outputs":[],"source":["# Read files\n","with zipfile.ZipFile('/content/IDSC2025_AnXplore03.zip', 'r') as zip_ref:\n","    zip_ref.extractall('/content/data/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hQCGzsxcRagA"},"outputs":[],"source":["xdmf_files = [f for f in os.listdir('/content/data/4Students_AnXplore03/') if f[-1] == 'f']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1324497,"status":"ok","timestamp":1737711550810,"user":{"displayName":"TR Fluide","userId":"15818092041118769586"},"user_tz":-60},"id":"f07e_EIlKCnA","outputId":"feb45266-a5d1-4cd8-f5c3-dfef04bcb9e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded 80 timesteps from AllFields_Resultats_MESH_192.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_183.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_182-1.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_117.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_195.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_152.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_159.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_205.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_153.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_211.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_158.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_180.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_186-1.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_191.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_157.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_1.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_171.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_181.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_198-2.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_26.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_2.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_186-2.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_155.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_138.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_164.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_182-2.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_197.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_217.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_54-1.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_203.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_213.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_170.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_128.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_168-1.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_165.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_162.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_144-2.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_44.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_202.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_193-1.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_166.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_9-1.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_42-2.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_210.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_177.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_142.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_42-1.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_148.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_135.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_31.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_175.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_34.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_188.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_28.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_139.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_121.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_42-3.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_54-2.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_219.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_161.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_163-2.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_55.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_168-2.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_136.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_215.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_137.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_199.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_178.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_200.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_19.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_207.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_182-3.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_204.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_23.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_185.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_140.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_25.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_163-1.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_209.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_173.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_214.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_174.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_206.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_196-2.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_3.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_120.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_40.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_193-2.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_129.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_119-2.xdmf\n","\n","Loaded 80 timesteps from AllFields_Resultats_MESH_151.xdmf\n","\n","Done collecting data!\n"]}],"source":["data_list = []\n","dt = 0.01\n","image_count = 0\n","for f in xdmf_files:\n","    if image_count > 90:\n","        break\n","    image_count += 1\n","    data = xdmf_to_meshes(f\"/content/data/4Students_AnXplore03/{f}\")\n","    node_type = np.zeros((len(data[0].point_data['Vitesse']), 9))\n","    #print(np.linalg.norm(data[0].point_data['Vitesse'], axis = 1).shape )\n","    node_type[np.linalg.norm(data[0].point_data['Vitesse'], axis=1) < 10e-10] = np.array([0, 0, 0, 0, 0, 0, 1, 0, 0])\n","    node_type[np.linalg.norm(data[0].point_data['Vitesse'], axis=1) > 10e-10] = np.array([1, 0, 0, 0, 0, 0, 0, 0, 0])\n","    node_type = torch.tensor(node_type)\n","    for ts in range(79):\n","\n","        # Note that it's faster to convert to numpy then to torch than to\n","        # import to torch from h5 format directly\n","        momentum = torch.tensor(np.array(data[ts].point_data['Vitesse']))\n","        # node_type = torch.tensor(np.array(data[ts].point_data['Vitesse'].shape[0]*[[1, 0, 0, 0, 0, 0, 0, 0, 0]]))\n","        x = torch.cat((momentum, node_type),dim=-1).type(torch.float)\n","\n","        # Get edge indices in COO format\n","        edges = tetra_to_edges(tf.convert_to_tensor(data[ts].cells_dict['tetra'].tolist()))\n","\n","        edge_index = torch.cat( (torch.tensor(edges[0].numpy()).unsqueeze(0),\n","                        torch.tensor(edges[1].numpy()).unsqueeze(0)), dim=0).type(torch.long)\n","\n","        # Get edge features\n","        u_i = torch.tensor(np.array(data[ts].points))[edge_index[0]]\n","        u_j = torch.tensor(np.array(data[ts].points))[edge_index[1]]\n","        u_ij = u_i-u_j\n","        u_ij_norm = torch.norm(u_ij, p=2, dim=1, keepdim=True)\n","        edge_attr = torch.cat((u_ij, u_ij_norm), dim=-1).type(torch.float)\n","\n","        # Node outputs, for training (velocity)\n","        v_t = torch.tensor(np.array(data[ts].point_data['Vitesse']))\n","        v_tp1=torch.tensor(np.array(data[ts+1].point_data['Vitesse']))\n","        y=((v_tp1-v_t)/dt).type(torch.float)\n","\n","        # Node outputs, for testing integrator (pressure)\n","        p = torch.tensor(np.array(data[ts].point_data['Pression']))\n","\n","        # Data needed for visualization code\n","        cells = torch.tensor(data[ts].cells_dict['tetra'])\n","        mesh_pos=torch.tensor(np.array(data[ts].points))\n","\n","        data_list.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr,y=y,p=p,\n","                                cells=cells,mesh_pos=mesh_pos))\n","\n","print(\"Done collecting data!\")\n","\n","# os.path.join(data_folder + '/test.h5')\n","# torch.save(data_list, os.path.join(data_folder + '/test_processed_set.pt'))\n","# torch.save(data_list,'./'+dataset_dir+'/test_processed_set.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JOy0GrPXKGUx"},"outputs":[],"source":["data_list2 = data_list[:5]"]},{"cell_type":"markdown","metadata":{"id":"xXI8_nzwKRCL"},"source":["### Normalization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"33f86TZKKJkD"},"outputs":[],"source":["def normalize(to_normalize,mean_vec,std_vec):\n","    return (to_normalize-mean_vec)/std_vec\n","\n","def unnormalize(to_unnormalize,mean_vec,std_vec):\n","    return to_unnormalize*std_vec+mean_vec\n","\n","def get_stats(data_list):\n","    '''\n","    Method for normalizing processed datasets. Given  the processed data_list,\n","    calculates the mean and standard deviation for the node features, edge features,\n","    and node outputs, and normalizes these using the calculated statistics.\n","    '''\n","\n","    #mean and std of the node features are calculated\n","    mean_vec_x=torch.zeros(data_list[0].x.shape[1:])\n","    std_vec_x=torch.zeros(data_list[0].x.shape[1:])\n","\n","    #mean and std of the edge features are calculated\n","    mean_vec_edge=torch.zeros(data_list[0].edge_attr.shape[1:])\n","    std_vec_edge=torch.zeros(data_list[0].edge_attr.shape[1:])\n","\n","    #mean and std of the output parameters are calculated\n","    mean_vec_y=torch.zeros(data_list[0].y.shape[1:])\n","    std_vec_y=torch.zeros(data_list[0].y.shape[1:])\n","\n","    #Define the maximum number of accumulations to perform such that we do\n","    #not encounter memory issues\n","    max_accumulations = 10**6\n","\n","    #Define a very small value for normalizing to\n","    eps=torch.tensor(1e-8)\n","\n","    #Define counters used in normalization\n","    num_accs_x = 0\n","    num_accs_edge=0\n","    num_accs_y=0\n","\n","    #Iterate through the data in the list to accumulate statistics\n","    for dp in data_list:\n","\n","        #Add to the\n","        mean_vec_x+=torch.sum(dp.x,dim=0)\n","        std_vec_x+=torch.sum(dp.x**2,dim=0)\n","        num_accs_x+=dp.x.shape[0]\n","\n","        mean_vec_edge+=torch.sum(dp.edge_attr,dim=0)\n","        std_vec_edge+=torch.sum(dp.edge_attr**2,dim=0)\n","        num_accs_edge+=dp.edge_attr.shape[0]\n","\n","        mean_vec_y+=torch.sum(dp.y,dim=0)\n","        std_vec_y+=torch.sum(dp.y**2,dim=0)\n","        num_accs_y+=dp.y.shape[0]\n","\n","        if(num_accs_x>max_accumulations or num_accs_edge>max_accumulations or num_accs_y>max_accumulations):\n","            break\n","\n","    mean_vec_x = mean_vec_x/num_accs_x\n","    std_vec_x = torch.maximum(torch.sqrt(std_vec_x/num_accs_x - mean_vec_x**2),eps)\n","\n","    mean_vec_edge = mean_vec_edge/num_accs_edge\n","    std_vec_edge = torch.maximum(torch.sqrt(std_vec_edge/num_accs_edge - mean_vec_edge**2),eps)\n","\n","    mean_vec_y = mean_vec_y/num_accs_y\n","    std_vec_y = torch.maximum(torch.sqrt(std_vec_y/num_accs_y - mean_vec_y**2),eps)\n","\n","    mean_std_list=[mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge,mean_vec_y,std_vec_y]\n","\n","    return mean_std_list"]},{"cell_type":"markdown","metadata":{"id":"VlfS8S1eKNVg"},"source":["### Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6-dqflvDKfKG"},"outputs":[],"source":["class ProcessorLayer(MessagePassing):\n","    def __init__(self, in_channels, out_channels,  **kwargs):\n","        super(ProcessorLayer, self).__init__(  **kwargs )\n","        \"\"\"\n","        in_channels: dim of node embeddings [128], out_channels: dim of edge embeddings [128]\n","\n","        \"\"\"\n","\n","        # Note that the node and edge encoders both have the same hidden dimension\n","        # size. This means that the input of the edge processor will always be\n","        # three times the specified hidden dimension\n","        # (input: adjacent node embeddings and self embeddings)\n","        self.edge_mlp = Sequential(Linear( 3* in_channels , out_channels),\n","                                   ReLU(),\n","                                   Linear( out_channels, out_channels),\n","                                   LayerNorm(out_channels))\n","\n","        self.node_mlp = Sequential(Linear( 2* in_channels , out_channels),\n","                                   ReLU(),\n","                                   Linear( out_channels, out_channels),\n","                                   LayerNorm(out_channels))\n","\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        \"\"\"\n","        reset parameters for stacked MLP layers\n","        \"\"\"\n","        self.edge_mlp[0].reset_parameters()\n","        self.edge_mlp[2].reset_parameters()\n","\n","        self.node_mlp[0].reset_parameters()\n","        self.node_mlp[2].reset_parameters()\n","\n","    def forward(self, x, edge_index, edge_attr, size = None):\n","        \"\"\"\n","        Handle the pre and post-processing of node features/embeddings,\n","        as well as initiates message passing by calling the propagate function.\n","\n","        Note that message passing and aggregation are handled by the propagate\n","        function, and the update\n","\n","        x has shpae [node_num , in_channels] (node embeddings)\n","        edge_index: [2, edge_num]\n","        edge_attr: [E, in_channels]\n","\n","        \"\"\"\n","\n","        out, updated_edges = self.propagate(edge_index, x = x, edge_attr = edge_attr, size = size) # out has the shape of [E, out_channels]\n","\n","        updated_nodes = torch.cat([x,out],dim=1)        # Complete the aggregation through self-aggregation\n","\n","        updated_nodes = x + self.node_mlp(updated_nodes) # residual connection\n","\n","        return updated_nodes, updated_edges\n","\n","    def message(self, x_i, x_j, edge_attr):\n","        \"\"\"\n","        source_node: x_i has the shape of [E, in_channels]\n","        target_node: x_j has the shape of [E, in_channels]\n","        target_edge: edge_attr has the shape of [E, out_channels]\n","\n","        The messages that are passed are the raw embeddings. These are not processed.\n","        \"\"\"\n","\n","        updated_edges=torch.cat([x_i, x_j, edge_attr], dim = 1) # tmp_emb has the shape of [E, 3 * in_channels]\n","        updated_edges=self.edge_mlp(updated_edges)+edge_attr\n","\n","        return updated_edges\n","\n","    def aggregate(self, updated_edges, edge_index, dim_size = None):\n","        \"\"\"\n","        First we aggregate from neighbors (i.e., adjacent nodes) through concatenation,\n","        then we aggregate self message (from the edge itself). This is streamlined\n","        into one operation here.\n","        \"\"\"\n","\n","        # The axis along which to index number of nodes.\n","        node_dim = 0\n","\n","        out = torch_scatter.scatter(updated_edges, edge_index[0, :], dim=node_dim, reduce = 'sum')\n","\n","        return out, updated_edges"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bRfrhHM4KMbJ"},"outputs":[],"source":["class MeshGraphNet(torch.nn.Module):\n","    def __init__(self, input_dim_node, input_dim_edge, hidden_dim, output_dim, args, emb=False):\n","        super(MeshGraphNet, self).__init__()\n","        \"\"\"\n","        MeshGraphNet model. This model is built upon Deepmind's 2021 paper.\n","        This model consists of three parts: (1) Preprocessing: encoder (2) Processor\n","        (3) postproccessing: decoder. Encoder has an edge and node decoders respectively.\n","        Processor has two processors for edge and node respectively. Note that edge attributes have to be\n","        updated first. Decoder is only for nodes.\n","\n","        Input_dim: dynamic variables + node_type + node_position\n","        Hidden_dim: 128 in deepmind's paper\n","        Output_dim: dynamic variables: velocity changes (1)\n","\n","        \"\"\"\n","\n","        self.num_layers = args.num_layers\n","\n","        # encoder convert raw inputs into latent embeddings\n","        self.node_encoder = Sequential(Linear(input_dim_node , hidden_dim),\n","                              ReLU(),\n","                              Linear( hidden_dim, hidden_dim),\n","                              LayerNorm(hidden_dim))\n","\n","        self.edge_encoder = Sequential(Linear( input_dim_edge , hidden_dim),\n","                              ReLU(),\n","                              Linear( hidden_dim, hidden_dim),\n","                              LayerNorm(hidden_dim)\n","                              )\n","\n","\n","        self.processor = nn.ModuleList()\n","        assert (self.num_layers >= 1), 'Number of message passing layers is not >=1'\n","\n","        processor_layer=self.build_processor_model()\n","        for _ in range(self.num_layers):\n","            self.processor.append(processor_layer(hidden_dim,hidden_dim))\n","\n","\n","        # decoder: only for node embeddings\n","        self.decoder = Sequential(Linear( hidden_dim , hidden_dim),\n","                              ReLU(),\n","                              Linear( hidden_dim, output_dim)\n","                              )\n","\n","\n","    def build_processor_model(self):\n","        return ProcessorLayer\n","\n","\n","    def forward(self,data,mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge):\n","        \"\"\"\n","        Encoder encodes graph (node/edge features) into latent vectors (node/edge embeddings)\n","        The return of processor is fed into the processor for generating new feature vectors\n","        \"\"\"\n","        x, edge_index, edge_attr, pressure = data.x, data.edge_index, data.edge_attr, data.p\n","\n","        x = normalize(x,mean_vec_x,std_vec_x)\n","        edge_attr=normalize(edge_attr,mean_vec_edge,std_vec_edge)\n","\n","        # Step 1: encode node/edge features into latent node/edge embeddings\n","        x = self.node_encoder(x) # output shape is the specified hidden dimension\n","\n","        edge_attr = self.edge_encoder(edge_attr) # output shape is the specified hidden dimension\n","\n","        # step 2: perform message passing with latent node/edge embeddings\n","        for i in range(self.num_layers):\n","            x,edge_attr = self.processor[i](x,edge_index,edge_attr)\n","\n","        # step 3: decode latent node embeddings into physical quantities of interest\n","\n","        return self.decoder(x)\n","\n","    def loss(self, pred, inputs,mean_vec_y,std_vec_y):\n","        #Define the node types that we calculate loss for\n","        normal=torch.tensor(0)\n","        outflow=torch.tensor(5)\n","\n","        #Get the loss mask for the nodes of the types we calculate loss for\n","        loss_mask=torch.logical_or((torch.argmax(inputs.x[:,3:],dim=1)==torch.tensor(0)),\n","                                   (torch.argmax(inputs.x[:,3:],dim=1)==torch.tensor(5)))\n","\n","        #Normalize labels with dataset statistics\n","        labels = normalize(inputs.y, mean_vec_y, std_vec_y)\n","        # print(inputs.y.shape)\n","        # print(\"------\")\n","        # print(pred.shape)\n","\n","\n","        #Find sum of square errors\n","        error=torch.sum((labels-pred)**2,axis=1)\n","\n","        #Root and mean the errors for the nodes we calculate loss for\n","        loss=torch.sqrt(torch.mean(error[loss_mask]))\n","\n","\n","        return loss"]},{"cell_type":"markdown","metadata":{"id":"uqLrWyRSKh4h"},"source":["### Optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yUCUJYtdKiqq"},"outputs":[],"source":["def build_optimizer(args, params):\n","    weight_decay = args.weight_decay\n","    filter_fn = filter(lambda p : p.requires_grad, params)\n","    if args.opt == 'adam':\n","        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n","    elif args.opt == 'sgd':\n","        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n","    elif args.opt == 'rmsprop':\n","        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n","    elif args.opt == 'adagrad':\n","        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n","    if args.opt_scheduler == 'none':\n","        return None, optimizer\n","    elif args.opt_scheduler == 'step':\n","        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n","    elif args.opt_scheduler == 'cos':\n","        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n","    return scheduler, optimizer"]},{"cell_type":"markdown","metadata":{"id":"T2tw1lY5KnKB"},"source":["### Training and testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BE9Z2HOFKi92"},"outputs":[],"source":["def train(dataset, device, stats_list, args):\n","    '''\n","    Performs a training loop on the dataset for MeshGraphNets. Also calls\n","    test and validation functions.\n","    '''\n","\n","    df = pd.DataFrame(columns=['epoch','train_loss','test_loss', 'velo_val_loss'])\n","\n","    #Define the model name for saving\n","    model_name='model_nl'+str(args.num_layers)+'_bs'+str(args.batch_size) + \\\n","               '_hd'+str(args.hidden_dim)+'_ep'+str(args.epochs)+'_wd'+str(args.weight_decay) + \\\n","               '_lr'+str(args.lr)+'_shuff_'+str(args.shuffle)+'_tr'+str(args.train_size)+'_te'+str(args.test_size)\n","\n","    #torch_geometric DataLoaders are used for handling the data of lists of graphs\n","    loader = DataLoader(dataset[:args.train_size], batch_size=args.batch_size, shuffle=False)\n","    # print(loader.batch_size)\n","    test_loader = DataLoader(dataset[args.train_size:], batch_size=args.batch_size, shuffle=False)\n","\n","    #The statistics of the data are decomposed\n","    [mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge,mean_vec_y,std_vec_y] = stats_list\n","    (mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge,mean_vec_y,std_vec_y)=(mean_vec_x.to(device),\n","        std_vec_x.to(device),mean_vec_edge.to(device),std_vec_edge.to(device),mean_vec_y.to(device),std_vec_y.to(device))\n","\n","    # build model\n","    num_node_features = dataset[0].x.shape[1]\n","    num_edge_features = dataset[0].edge_attr.shape[1]\n","    num_classes = 3 # the dynamic variables have the shape of 2 (velocity)\n","\n","    model = MeshGraphNet(num_node_features, num_edge_features, args.hidden_dim, num_classes,\n","                            args).to(device)\n","    scheduler, opt = build_optimizer(args, model.parameters())\n","\n","    # train\n","    losses = []\n","    test_losses = []\n","    velo_val_losses = []\n","    best_test_loss = np.inf\n","    best_model = None\n","    for epoch in trange(args.epochs, desc=\"Training\", unit=\"Epochs\"):\n","        total_loss = 0\n","        model.train()\n","        num_loops=0\n","        for batch in loader:\n","            #Note that normalization must be done before it's called. The unnormalized\n","            #data needs to be preserved in order to correctly calculate the loss\n","            batch=batch.to(device)\n","            opt.zero_grad()         #zero gradients each time\n","            pred = model(batch,mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge)\n","            loss = model.loss(pred,batch,mean_vec_y,std_vec_y)\n","            loss.backward()         #backpropagate loss\n","            opt.step()\n","            total_loss += loss.item()\n","            num_loops+=1\n","        total_loss /= num_loops\n","        losses.append(total_loss)\n","\n","        #Every tenth epoch, calculate acceleration test loss and velocity validation loss\n","        if epoch % 10 == 0:\n","            if (args.save_velo_val):\n","                # save velocity evaluation\n","                test_loss, velo_val_rmse = test(test_loader,device,model,mean_vec_x,std_vec_x,mean_vec_edge,\n","                                 std_vec_edge,mean_vec_y,std_vec_y, args.save_velo_val)\n","                velo_val_losses.append(velo_val_rmse.item())\n","            else:\n","                test_loss, _ = test(test_loader,device,model,mean_vec_x,std_vec_x,mean_vec_edge,\n","                                 std_vec_edge,mean_vec_y,std_vec_y, args.save_velo_val)\n","\n","            test_losses.append(test_loss.item())\n","\n","            # saving model\n","            if not os.path.isdir( args.checkpoint_dir ):\n","                os.mkdir(args.checkpoint_dir)\n","\n","            PATH = os.path.join(args.checkpoint_dir, model_name+'.csv')\n","            df.to_csv(PATH,index=False)\n","\n","            #save the model if the current one is better than the previous best\n","            if test_loss < best_test_loss:\n","                best_test_loss = test_loss\n","                best_model = copy.deepcopy(model)\n","\n","        else:\n","            #If not the tenth epoch, append the previously calculated loss to the\n","            #list in order to be able to plot it on the same plot as the training losses\n","            if (args.save_velo_val):\n","              test_losses.append(test_losses[-1])\n","              velo_val_losses.append(velo_val_losses[-1])\n","\n","        if (args.save_velo_val):\n","            df = pd.concat([df, pd.DataFrame({'epoch': [epoch],'train_loss': [losses[-1]],\n","                            'test_loss': [test_losses[-1]],\n","                           'velo_val_loss': [velo_val_losses[-1]]})], ignore_index=True)\n","        else:\n","            df = pd.concat([df, pd.DataFrame({'epoch': [epoch], 'train_loss': [losses[-1]], 'test_loss': [test_losses[-1]]})], ignore_index=True)\n","        if(epoch%1==0):\n","            if (args.save_velo_val):\n","                print(\"train loss\", str(round(total_loss, 2)),\n","                      \"test loss\", str(round(test_loss.item(), 2)),\n","                      \"velo loss\", str(round(velo_val_rmse.item(), 5)))\n","            else:\n","                print(\"train loss\", str(round(total_loss,2)), \"test loss\", str(round(test_loss.item(),2)))\n","\n","\n","            if(args.save_best_model):\n","\n","                PATH = os.path.join(args.checkpoint_dir, model_name+'.pt')\n","                torch.save(best_model.state_dict(), PATH )\n","\n","    return test_losses, losses, velo_val_losses, best_model, best_test_loss, test_loader\n","\n","def test(loader,device,test_model,\n","         mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge,mean_vec_y,std_vec_y, is_validation,\n","          delta_t=0.01, save_model_preds=False, model_type=None):\n","\n","    '''\n","    Calculates test set losses and validation set errors.\n","    '''\n","\n","    loss=0\n","    velo_rmse = 0\n","    num_loops=0\n","\n","    for data in loader:\n","        data=data.to(device)\n","        with torch.no_grad():\n","\n","            #calculate the loss for the model given the test set\n","            pred = test_model(data,mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge)\n","            loss += test_model.loss(pred, data,mean_vec_y,std_vec_y)\n","\n","            #calculate validation error if asked to\n","            if (is_validation):\n","\n","                #Like for the MeshGraphNets model, calculate the mask over which we calculate\n","                #flow loss and add this calculated RMSE value to our val error\n","                normal = torch.tensor(0)\n","                outflow = torch.tensor(5)\n","                loss_mask = torch.logical_or((torch.argmax(data.x[:, 3:], dim=1) == torch.tensor(0)),\n","                                             (torch.argmax(data.x[:, 3:], dim=1) == torch.tensor(5)))\n","\n","                eval_velo = data.x[:, 0:3] + unnormalize( pred[:], mean_vec_y, std_vec_y ) * delta_t\n","                gs_velo = data.x[:, 0:3] + data.y[:] * delta_t\n","\n","                error = torch.sum((eval_velo - gs_velo) ** 2, axis=1)\n","                velo_rmse += torch.sqrt(torch.mean(error[loss_mask]))\n","\n","        num_loops+=1\n","        # if velocity is evaluated, return velo_rmse as 0\n","    return loss/num_loops, velo_rmse/num_loops"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1737711550813,"user":{"displayName":"TR Fluide","userId":"15818092041118769586"},"user_tz":-60},"id":"xM_MksgFTkEK","outputId":"cbb77a27-f60a-430d-c190-866249c3ae3b"},"outputs":[{"data":{"text/plain":["7189"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["len(data_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8J65eIBtKouY"},"outputs":[],"source":["class objectview(object):\n","    def __init__(self, d):\n","        self.__dict__ = d\n","\n","for args in [\n","        {'model_type': 'meshgraphnet',\n","         'num_layers': 10,\n","         'batch_size': 4,\n","         'hidden_dim': 100,\n","         'epochs': 100,\n","         'opt': 'adam',\n","         'opt_scheduler': 'none',\n","         'opt_restart': 0,\n","         'weight_decay': 5e-4,\n","         'lr': 0.00001,\n","         'train_size': 5800,\n","         'test_size': 1400,\n","         'device':'cuda',\n","         'shuffle': True,\n","         'save_velo_val': True,\n","         'save_best_model': True,\n","         'checkpoint_dir': '/content/gdrive/My Drive/Groupe4/best_models/',\n","         'postprocess_dir': './2d_loss_plots/'},\n","    ]:\n","        args = objectview(args)\n","\n","#To ensure reproducibility the best we can, here we control the sources of\n","#randomness by seeding the various random number generators used in this Colab\n","#For more information, see: https://pytorch.org/docs/stable/notes/randomness.html\n","torch.manual_seed(5)  #Torch\n","random.seed(5)        #Python\n","np.random.seed(5)     #NumPy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1737711550814,"user":{"displayName":"TR Fluide","userId":"15818092041118769586"},"user_tz":-60},"id":"ryXR8f6eKrNT","outputId":"68da062c-2b5e-46ba-a947-6d38aa7dd860"},"outputs":[{"data":{"text/plain":["7189"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["dataset = data_list\n","len(dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1737711550814,"user":{"displayName":"TR Fluide","userId":"15818092041118769586"},"user_tz":-60},"id":"0peu4wXlKtPf","outputId":"63e5de7d-8a0b-4370-8da7-c786b447a24a"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["if(args.shuffle):\n","  random.shuffle(dataset)\n","\n","stats_list = get_stats(dataset)\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","args.device = device\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":612,"status":"ok","timestamp":1737711792652,"user":{"displayName":"TR Fluide","userId":"15818092041118769586"},"user_tz":-60},"id":"9Q7BC3kwr7LL","outputId":"531697cd-b785-4ea7-d51b-a940df6bbb5f"},"outputs":[{"data":{"text/plain":["3616"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["import gc\n","torch. cuda. empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":873},"id":"kUrBKDHHKvyI","executionInfo":{"status":"error","timestamp":1737724142950,"user_tz":-60,"elapsed":4133,"user":{"displayName":"TR Fluide","userId":"15818092041118769586"}},"outputId":"5bd8e88b-b3f9-4a43-8d3b-fcd6a421ea19"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n","  warnings.warn(out)\n","Training:   0%|          | 0/100 [00:00<?, ?Epochs/s]<ipython-input-23-8526c2f64fd0>:90: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  df = pd.concat([df, pd.DataFrame({'epoch': [epoch],'train_loss': [losses[-1]],\n","Training:   1%|          | 1/100 [09:15<15:16:19, 555.35s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.43 test loss 1.31 velo loss 14.11493\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:   2%|▏         | 2/100 [17:39<14:18:00, 525.31s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.42 test loss 1.31 velo loss 14.11493\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:   3%|▎         | 3/100 [26:04<13:53:56, 515.84s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.42 test loss 1.31 velo loss 14.11493\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:   4%|▍         | 4/100 [34:28<13:38:09, 511.35s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.41 test loss 1.31 velo loss 14.11493\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:   5%|▌         | 5/100 [42:53<13:25:49, 508.94s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.41 test loss 1.31 velo loss 14.11493\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:   6%|▌         | 6/100 [51:17<13:15:02, 507.48s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.41 test loss 1.31 velo loss 14.11493\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:   7%|▋         | 7/100 [59:42<13:05:13, 506.60s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.4 test loss 1.31 velo loss 14.11493\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:   8%|▊         | 8/100 [1:08:07<12:55:38, 505.86s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.4 test loss 1.31 velo loss 14.11493\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:   9%|▉         | 9/100 [1:16:31<12:46:34, 505.43s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.39 test loss 1.31 velo loss 14.11493\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:  10%|█         | 10/100 [1:24:56<12:37:44, 505.17s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.39 test loss 1.31 velo loss 14.11493\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:  11%|█         | 11/100 [1:34:11<12:52:04, 520.50s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.38 test loss 1.28 velo loss 13.90703\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:  12%|█▏        | 12/100 [1:42:35<12:36:13, 515.61s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.38 test loss 1.28 velo loss 13.90703\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:  13%|█▎        | 13/100 [1:51:00<12:22:45, 512.25s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.37 test loss 1.28 velo loss 13.90703\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:  14%|█▍        | 14/100 [1:59:24<12:10:55, 509.95s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.37 test loss 1.28 velo loss 13.90703\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:  15%|█▌        | 15/100 [2:07:49<12:00:17, 508.44s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.36 test loss 1.28 velo loss 13.90703\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:  16%|█▌        | 16/100 [2:16:15<11:50:29, 507.49s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.35 test loss 1.28 velo loss 13.90703\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:  17%|█▋        | 17/100 [2:24:39<11:40:52, 506.66s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.34 test loss 1.28 velo loss 13.90703\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:  18%|█▊        | 18/100 [2:33:04<11:31:36, 506.06s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.33 test loss 1.28 velo loss 13.90703\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:  19%|█▉        | 19/100 [2:41:29<11:22:52, 505.84s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.31 test loss 1.28 velo loss 13.90703\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:  20%|██        | 20/100 [2:49:54<11:14:07, 505.59s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.29 test loss 1.28 velo loss 13.90703\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:  21%|██        | 21/100 [2:59:10<11:25:32, 520.67s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.27 test loss 1.18 velo loss 12.94714\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:  22%|██▏       | 22/100 [3:07:35<11:10:49, 516.01s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.24 test loss 1.18 velo loss 12.94714\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:  23%|██▎       | 23/100 [3:16:00<10:57:56, 512.68s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.22 test loss 1.18 velo loss 12.94714\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rTraining:  24%|██▍       | 24/100 [3:24:25<10:46:24, 510.33s/Epochs]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss 1.19 test loss 1.18 velo loss 12.94714\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining:  24%|██▍       | 24/100 [3:25:45<10:51:33, 514.38s/Epochs]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-495c60f31150>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvelo_val_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_test_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Min test set loss: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Minimum loss: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_velo_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-8526c2f64fd0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, device, stats_list, args)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m#backpropagate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mnum_loops\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnum_loops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["test_losses, losses, velo_val_losses, best_model, best_test_loss, test_loader = train(dataset, device, stats_list, args)\n","\n","print(\"Min test set loss: {0}\".format(min(test_losses)))\n","print(\"Minimum loss: {0}\".format(min(losses)))\n","if (args.save_velo_val):\n","    print(\"Minimum velocity validation loss: {0}\".format(min(velo_val_losses)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c6FtM3Y1SPVL"},"outputs":[],"source":["while True:\n","  time.sleep(10)"]},{"cell_type":"markdown","metadata":{"id":"8oNQauzYSEeo"},"source":["### Loading the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":808,"status":"error","timestamp":1737662119549,"user":{"displayName":"TR Fluide","userId":"15818092041118769586"},"user_tz":-60},"id":"ZUA7LBfVR7u4","outputId":"c2a735e2-4a02-4c21-a345-69a85ca505bb"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-30-38a02544f287>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(PATH, map_location=args.device))\n"]},{"ename":"RuntimeError","evalue":"Error(s) in loading state_dict for MeshGraphNet:\n\tsize mismatch for node_encoder.0.weight: copying a param with shape torch.Size([10, 12]) from checkpoint, the shape in current model is torch.Size([20, 12]).\n\tsize mismatch for node_encoder.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for node_encoder.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for node_encoder.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for node_encoder.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for node_encoder.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for edge_encoder.0.weight: copying a param with shape torch.Size([10, 4]) from checkpoint, the shape in current model is torch.Size([20, 4]).\n\tsize mismatch for edge_encoder.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for edge_encoder.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for edge_encoder.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for edge_encoder.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for edge_encoder.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.0.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.0.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.0.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.0.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.0.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.0.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.0.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.0.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.0.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.0.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.0.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.0.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.1.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.1.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.1.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.1.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.1.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.1.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.1.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.1.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.1.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.1.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.1.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.1.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.2.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.2.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.2.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.2.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.2.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.2.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.2.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.2.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.2.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.2.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.2.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.2.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.3.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.3.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.3.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.3.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.3.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.3.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.3.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.3.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.3.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.3.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.3.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.3.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.4.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.4.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.4.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.4.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.4.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.4.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.4.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.4.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.4.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.4.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.4.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.4.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.5.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.5.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.5.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.5.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.5.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.5.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.5.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.5.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.5.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.5.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.5.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.5.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.6.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.6.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.6.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.6.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.6.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.6.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.6.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.6.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.6.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.6.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.6.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.6.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.7.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.7.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.7.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.7.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.7.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.7.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.7.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.7.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.7.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.7.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.7.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.7.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.8.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.8.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.8.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.8.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.8.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.8.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.8.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.8.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.8.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.8.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.8.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.8.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.9.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.9.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.9.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.9.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.9.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.9.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.9.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.9.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.9.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.9.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.9.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.9.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.10.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.10.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.10.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.10.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.10.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.10.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.10.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.10.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.10.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.10.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.10.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.10.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.11.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.11.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.11.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.11.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.11.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.11.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.11.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.11.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.11.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.11.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.11.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.11.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.12.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.12.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.12.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.12.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.12.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.12.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.12.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.12.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.12.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.12.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.12.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.12.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.13.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.13.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.13.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.13.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.13.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.13.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.13.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.13.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.13.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.13.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.13.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.13.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.14.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.14.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.14.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.14.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.14.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.14.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.14.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.14.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.14.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.14.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.14.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.14.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.15.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.15.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.15.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.15.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.15.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.15.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.15.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.15.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.15.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.15.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.15.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.15.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.16.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.16.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.16.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.16.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.16.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.16.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.16.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.16.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.16.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.16.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.16.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.16.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.17.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.17.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.17.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.17.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.17.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.17.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.17.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.17.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.17.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.17.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.17.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.17.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.18.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.18.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.18.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.18.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.18.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.18.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.18.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.18.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.18.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.18.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.18.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.18.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.19.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.19.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.19.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.19.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.19.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.19.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.19.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.19.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.19.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.19.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.19.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.19.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for decoder.0.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for decoder.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for decoder.2.weight: copying a param with shape torch.Size([3, 10]) from checkpoint, the shape in current model is torch.Size([3, 20]).","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-38a02544f287>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                             args).to(args.device)\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2584\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2585\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2586\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MeshGraphNet:\n\tsize mismatch for node_encoder.0.weight: copying a param with shape torch.Size([10, 12]) from checkpoint, the shape in current model is torch.Size([20, 12]).\n\tsize mismatch for node_encoder.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for node_encoder.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for node_encoder.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for node_encoder.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for node_encoder.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for edge_encoder.0.weight: copying a param with shape torch.Size([10, 4]) from checkpoint, the shape in current model is torch.Size([20, 4]).\n\tsize mismatch for edge_encoder.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for edge_encoder.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for edge_encoder.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for edge_encoder.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for edge_encoder.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.0.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.0.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.0.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.0.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.0.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.0.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.0.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.0.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.0.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.0.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.0.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.0.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.1.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.1.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.1.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.1.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.1.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.1.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.1.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.1.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.1.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.1.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.1.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.1.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.2.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.2.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.2.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.2.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.2.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.2.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.2.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.2.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.2.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.2.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.2.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.2.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.3.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.3.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.3.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.3.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.3.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.3.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.3.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.3.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.3.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.3.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.3.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.3.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.4.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.4.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.4.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.4.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.4.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.4.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.4.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.4.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.4.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.4.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.4.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.4.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.5.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.5.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.5.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.5.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.5.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.5.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.5.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.5.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.5.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.5.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.5.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.5.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.6.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.6.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.6.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.6.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.6.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.6.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.6.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.6.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.6.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.6.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.6.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.6.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.7.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.7.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.7.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.7.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.7.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.7.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.7.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.7.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.7.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.7.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.7.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.7.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.8.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.8.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.8.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.8.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.8.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.8.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.8.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.8.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.8.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.8.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.8.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.8.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.9.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.9.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.9.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.9.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.9.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.9.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.9.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.9.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.9.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.9.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.9.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.9.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.10.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.10.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.10.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.10.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.10.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.10.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.10.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.10.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.10.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.10.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.10.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.10.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.11.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.11.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.11.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.11.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.11.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.11.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.11.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.11.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.11.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.11.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.11.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.11.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.12.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.12.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.12.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.12.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.12.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.12.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.12.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.12.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.12.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.12.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.12.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.12.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.13.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.13.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.13.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.13.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.13.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.13.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.13.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.13.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.13.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.13.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.13.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.13.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.14.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.14.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.14.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.14.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.14.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.14.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.14.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.14.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.14.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.14.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.14.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.14.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.15.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.15.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.15.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.15.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.15.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.15.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.15.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.15.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.15.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.15.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.15.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.15.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.16.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.16.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.16.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.16.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.16.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.16.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.16.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.16.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.16.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.16.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.16.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.16.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.17.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.17.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.17.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.17.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.17.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.17.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.17.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.17.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.17.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.17.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.17.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.17.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.18.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.18.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.18.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.18.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.18.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.18.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.18.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.18.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.18.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.18.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.18.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.18.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.19.edge_mlp.0.weight: copying a param with shape torch.Size([10, 30]) from checkpoint, the shape in current model is torch.Size([20, 60]).\n\tsize mismatch for processor.19.edge_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.19.edge_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.19.edge_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.19.edge_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.19.edge_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.19.node_mlp.0.weight: copying a param with shape torch.Size([10, 20]) from checkpoint, the shape in current model is torch.Size([20, 40]).\n\tsize mismatch for processor.19.node_mlp.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.19.node_mlp.2.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for processor.19.node_mlp.2.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.19.node_mlp.3.weight: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for processor.19.node_mlp.3.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for decoder.0.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for decoder.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for decoder.2.weight: copying a param with shape torch.Size([3, 10]) from checkpoint, the shape in current model is torch.Size([3, 20])."]}],"source":["# Load model\n","args.device = torch.device('cpu') # animation function cannot work with data on GPU\n","num_node_features = dataset[0].x.shape[1]\n","num_edge_features = dataset[0].edge_attr.shape[1]\n","num_classes = 3 # the dynamic variables have the shape of 3 (velocity)\n","PATH = os.path.join('/content/gdrive/My Drive/Groupe4/best_models/', 'model_nl20_bs1_hd10_ep99_wd0.0005_lr0.001_shuff_True_tr3_te2.pt')\n","model = MeshGraphNet(num_node_features, num_edge_features, args.hidden_dim, num_classes,\n","                            args).to(args.device)\n","\n","model.load_state_dict(torch.load(PATH, map_location=args.device))"]},{"cell_type":"markdown","metadata":{"id":"VZXUrq6tXd2y"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OmCMmG-dSL3n"},"outputs":[],"source":["iteration = 0\n","[mean_vec_x, std_vec_x, mean_vec_edge, std_vec_edge, mean_vec_y, std_vec_y] = get_stats(dataset)\n","for data in dataset:\n","    if iteration == 1:\n","        break\n","    iteration += 1\n","    pred = model(data, mean_vec_x, std_vec_x, mean_vec_edge, std_vec_edge)"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"-WdjVoLoSMWR","executionInfo":{"status":"ok","timestamp":1737724230740,"user_tz":-60,"elapsed":183,"user":{"displayName":"TR Fluide","userId":"15818092041118769586"}}},"outputs":[],"source":["def save_plots(args, losses, test_losses, velo_val_losses):\n","    model_name='model_nl'+str(args.num_layers)+'_bs'+str(args.batch_size) + \\\n","               '_hd'+str(args.hidden_dim)+'_ep'+str(args.epochs)+'_wd'+str(args.weight_decay) + \\\n","               '_lr'+str(args.lr)+'_shuff_'+str(args.shuffle)+'_tr'+str(args.train_size)+'_te'+str(args.test_size)\n","\n","    # if not os.path.isdir(args.postprocess_dir):\n","    #     os.mkdir(args.postprocess_dir)\n","\n","    PATH = os.path.join(args.postprocess_dir, model_name + '.pdf')\n","\n","    f = plt.figure()\n","    plt.title('Losses Plot')\n","    plt.plot(losses, label=\"training loss\" + \" - \" + args.model_type)\n","    plt.plot(test_losses, label=\"test loss\" + \" - \" + args.model_type)\n","    #if (args.save_velo_val):\n","    #    plt.plot(velo_val_losses, label=\"velocity loss\" + \" - \" + args.model_type)\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","\n","    plt.legend()\n","    plt.show()\n","    # f.savefig(PATH, bbox_inches='tight')"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":507,"status":"ok","timestamp":1737724599464,"user":{"displayName":"TR Fluide","userId":"15818092041118769586"},"user_tz":-60},"id":"Ia7OwY8USOPk","outputId":"3302a242-ffb6-4ccb-a626-f3fb2679750b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["import pandas as pd\n","df = pd.read_csv(\"/content/gdrive/My Drive/Groupe4/best_models/model_nl20_bs1_hd10_ep99_wd0.0005_lr0.001_shuff_True_tr3_te2.csv\")\n","#print(losses)\n","\n","save_plots(args,df[\"train_loss\"], df[\"test_loss\"], df[\"test_loss\"])"]},{"cell_type":"code","source":["data_list[0].x[:,:3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rEqn1ctvgeDf","executionInfo":{"status":"ok","timestamp":1737725562807,"user_tz":-60,"elapsed":154,"user":{"displayName":"TR Fluide","userId":"15818092041118769586"}},"outputId":"b0a19d42-5517-4940-dd82-eff701b3efc1"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 3.6499e-14, -3.2506e-14, -4.2059e-15],\n","        [ 4.4503e-16, -8.5296e-16,  6.4861e-17],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        ...,\n","        [ 5.8499e+01, -4.1504e+01, -2.5903e+01],\n","        [ 3.0462e+02, -2.1420e+02, -1.3215e+01],\n","        [ 3.6148e+02, -1.6169e+02, -1.3307e+01]])"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["data_list[0].y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3vY831dOgrV-","executionInfo":{"status":"ok","timestamp":1737725701212,"user_tz":-60,"elapsed":151,"user":{"displayName":"TR Fluide","userId":"15818092041118769586"}},"outputId":"57b0b522-5779-4d62-9cd5-77ab49d95205"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-6.2323e-14,  5.4279e-14,  1.6210e-15],\n","        [-5.4267e-16,  1.1093e-15, -1.7142e-16],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        ...,\n","        [-1.2101e+02,  9.1078e+01,  7.6630e+01],\n","        [-2.9521e+02,  1.9721e+02, -6.6920e+01],\n","        [-4.7249e+02,  1.1157e+02, -3.6285e+01]])"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["def loss (pred, label):\n","  return torch.mean((pred-label)**2)/len(pred)\n","loss(data_list[0].x[:,:3],data_list[0].y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TDn_qCxuhBpE","executionInfo":{"status":"ok","timestamp":1737725802796,"user_tz":-60,"elapsed":174,"user":{"displayName":"TR Fluide","userId":"15818092041118769586"}},"outputId":"ed97f926-8a94-4371-c925-c9a857a424a3"},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(6.9251)"]},"metadata":{},"execution_count":54}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}